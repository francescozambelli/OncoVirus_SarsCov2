{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import graph_tool as gt\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from functools import reduce\n",
    "import itertools\n",
    "import scipy.sparse as sps\n",
    "import random\n",
    "import os\n",
    "#from pymnet import *\n",
    "\n",
    "import MuxVizPy as mxp\n",
    "\n",
    "import gseapy as gp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#set.seed(1)\n",
    "\n",
    "# input data settings\n",
    "NEIGH_ORDER = 1 # or 0, order of nerighbors, 0 only connected proteins, 1 also first neighbors\n",
    "CUT_THR = 0.7   # don't change this one\n",
    "\n",
    "target_folder = \"../Data/Virus_data_Enriched_\"+str(CUT_THR)+\"_Neigh_\"+str(NEIGH_ORDER)+\"/\"\n",
    "\n",
    "# multilayer settings\n",
    "layerCouplingStrength = 1\n",
    "networkOfLayersType = \"categorical\" ## = all to all\n",
    "\n",
    "#virus metadata\n",
    "virus_metadata = pd.read_csv(\"../Data/Files/viruses_metadata.csv\", header=0, sep=\";\")\n",
    "\n",
    "virus_metadata_onco = virus_metadata[virus_metadata[\"isOncogenic\"] == True].reset_index()\n",
    "virus_metadata_nonco = virus_metadata[virus_metadata[\"isOncogenic\"] == False].reset_index()\n",
    "\n",
    "#dictionary containing a unquie mapping between name of the protein and a corresponding index\n",
    "node_map_df = pd.read_csv(\"../Data/Files/node_map.csv\")\n",
    "node_map_dict = {k:(v-1) for k,v in zip(node_map_df[\"Prot\"], node_map_df[\"Index\"])}\n",
    "\n",
    "#function to create list of n_iter combination of nonco virus indexes with a fixed random seed for repitibility\n",
    "def SamplingForNoco(n_iter, start=0, group_dim=8, random_seed=1234):\n",
    "    np.random.seed(random_seed)\n",
    "    nonco_cond = np.where(np.all([np.array(virus_metadata[\"virus\"]!=\"Human_SARS_coronavirus_2\"),\n",
    "                                  np.array(virus_metadata[\"virus_short\"]!=\"Lymphocytic_choriomeningitis_virus\"),\n",
    "                                  np.array(virus_metadata[\"neigh_order\"]==NEIGH_ORDER), \n",
    "                                  np.array(virus_metadata[\"isOncogenic\"]==False)],\n",
    "                                  axis=0))\n",
    "    \n",
    "    nonco_sampling = np.array([np.random.choice(nonco_cond[0], group_dim, replace=False) for i in range(n_iter+start)])\n",
    "    return nonco_sampling[start:(n_iter+start)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for o in onco_virus_indexes:\n",
    "    np.savetxt(X = np.where([o in v for v in n1o_virus_indexes])[0], fname=str(o)+\"_index.txt\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.savetxt(X = np.where([67 in v for v in n1o_virus_indexes])[0], fname=\"67_index.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39,  1, 87, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1o_virus_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_iters = 3000\n",
    "np.random.seed(100)\n",
    "\n",
    "Sars_pos = np.where(np.array(np.all([virus_metadata[\"neigh_order\"]==NEIGH_ORDER, virus_metadata[\"virus\"]==\"Human_SARS_coronavirus_2\"], axis=0)))[0][0]\n",
    "onco_virus_indexes = np.where(np.array(np.all([virus_metadata[\"neigh_order\"]==NEIGH_ORDER, virus_metadata[\"isOncogenic\"] == True], axis=0)))[0]\n",
    "\n",
    "\n",
    "#N\n",
    "n_virus_indexes = SamplingForNoco(n_iters, group_dim=4, random_seed=41252145)\n",
    "\n",
    "\n",
    "#N1O\n",
    "n1o_virus_indexes = []\n",
    "n1o_sampling = SamplingForNoco(n_iters, group_dim=3, random_seed=456)\n",
    "for i in range(len(n1o_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes)\n",
    "    n1o_virus_indexes.append(np.concatenate([n1o_sampling[i], [onco_pick]]))\n",
    "\n",
    "#N1S\n",
    "Snonco_nonco_samples = SamplingForNoco(n_iters, group_dim=3, random_seed=4563)\n",
    "n1s_virus_indexes = np.concatenate([Snonco_nonco_samples, np.repeat(Sars_pos,n_iters).reshape([n_iters,1])], axis=1)\n",
    "    \n",
    "#N2O\n",
    "n2o_virus_indexes = []\n",
    "n2o_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=17521)\n",
    "for i in range(len(n2o_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes, 2)\n",
    "    n2o_virus_indexes.append(np.concatenate([n2o_sampling[i], onco_pick]))\n",
    "    \n",
    "#N3O\n",
    "comb = list(itertools.combinations(range(8), 3))\n",
    "o1n_onco_comb = [list(onco_virus_indexes[list(comb[i])]) for i in range(len(comb))]\n",
    "\n",
    "nonco_positions = np.where(np.all([np.array(virus_metadata[\"virus\"]!=\"Human_SARS_coronavirus_2\"),\n",
    "                                  np.array(virus_metadata[\"virus_short\"]!=\"Lymphocytic_choriomeningitis_virus\"),\n",
    "                                  np.array(virus_metadata[\"neigh_order\"]==NEIGH_ORDER), \n",
    "                                  np.array(virus_metadata[\"isOncogenic\"]==False)],\n",
    "                                  axis=0))[0]\n",
    "n3o_virus_indexes = random.sample(set(itertools.product(np.arange(len(o1n_onco_comb)), nonco_positions)), n_iters)\n",
    "n3o_virus_indexes = [np.concatenate([list(o1n_onco_comb[i[0]]), [i[1]]]) for i in n3o_virus_indexes]\n",
    "\n",
    "#O\n",
    "comb = list(itertools.combinations(range(8), 4))\n",
    "o_virus_indexes = np.array([list(onco_virus_indexes[list(comb[i])]) for i in range(len(comb))])\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#N1S\n",
    "Snonco_nonco_samples = SamplingForNoco(n_iters, group_dim=3, random_seed=4563)\n",
    "n1s_virus_indexes = np.concatenate([Snonco_nonco_samples, np.repeat(Sars_pos,n_iters).reshape([n_iters,1])], axis=1)\n",
    "\n",
    "#N1O1S\n",
    "n1o1s_virus_indexes = []\n",
    "n1o1s_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=783)\n",
    "for i in range(len(n1o1s_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes)\n",
    "    n1o1s_virus_indexes.append(np.concatenate([n1o1s_sampling[i], [onco_pick], [Sars_pos]]))\n",
    "    \n",
    "#N2O1S\n",
    "n2o1s_virus_indexes = []\n",
    "n2o1s_sampling = SamplingForNoco(n_iters, group_dim=1, random_seed=154)\n",
    "for i in range(len(n2o1s_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes,2)\n",
    "    n2o1s_virus_indexes.append(np.concatenate([n2o1s_sampling[i], onco_pick, [Sars_pos]]))\n",
    "    \n",
    "#O1S\n",
    "comb = list(itertools.combinations(range(8), 3))\n",
    "Sars_pos = np.where(np.array(np.all([virus_metadata[\"neigh_order\"]==NEIGH_ORDER, virus_metadata[\"virus\"]==\"Human_SARS_coronavirus_2\"], axis=0)))[0][0]\n",
    "o1s_virus_indexes = np.array([list(onco_virus_indexes[list(comb[i])])+[Sars_pos] for i in range(len(comb))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 3000, 'n1o': 3000}\n"
     ]
    }
   ],
   "source": [
    "index_lists = [n_virus_indexes,\n",
    "               n1o_virus_indexes, \n",
    "               #n2o_virus_indexes, \n",
    "               #n3o_virus_indexes,\n",
    "               #o_virus_indexes, \n",
    "               #n1s_virus_indexes,\n",
    "               #n1o1s_virus_indexes,\n",
    "               #n2o1s_virus_indexes,\n",
    "               #o1s_virus_indexes\n",
    "               ]\n",
    "\n",
    "names_lists=[\"n\", \n",
    "             \"n1o\", \n",
    "             #\"n2o\", \n",
    "             #\"n3o\", \n",
    "             #\"o\", \n",
    "             #\"n1s\", \n",
    "             #\"n1o1s\", \n",
    "             #\"n2o1s\", \n",
    "             #\"o1s\"\n",
    "             ]\n",
    "print(dict(zip(names_lists, [len(ioo) for ioo in index_lists])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▊                           | 246/930 [1:19:27<3:43:36, 19.61s/it]"
     ]
    }
   ],
   "source": [
    "########################################PERC CRITP#######################################################\n",
    "\n",
    "for i in tqdm(range(70,1000)):\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationData_4vir/topology/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationData_4vir/topology/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "\n",
    "        tensor=mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "\n",
    "        order = mxp.versatility.get_multi_RW_centrality_edge_colored(tensor)\n",
    "        order = order.sort_values(\"vers\")[\"phy nodes\"].to_numpy()\n",
    "        g_agg = mxp.build.get_aggregate_network(tensor)\n",
    "    \n",
    "        perc_agg_2 = gt.topology.vertex_percolation(g_agg, order, second=True)[0]\n",
    "        max_perc = np.argmax(perc_agg_2)/len(perc_agg_2)\n",
    "        \n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/Perc/\"+nam+\".txt\"):\n",
    "            np.savetxt(X=[max_perc], fname=\"../Data/ComponentsNew/Perc/\"+nam+\".txt\", fmt=\"%.5f\")\n",
    "        else:\n",
    "            perc_list = np.loadtxt(\"../Data/ComponentsNew/Perc/\"+nam+\".txt\")\n",
    "            if perc_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[perc_list],[max_perc]]), fname=\"../Data/ComponentsNew/Perc/\"+nam+\".txt\", fmt=\"%.5f\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([perc_list,[max_perc]]), fname=\"../Data/ComponentsNew/Perc/\"+nam+\".txt\", fmt=\"%.5f\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################COMPONENTS##################################################################\n",
    "\n",
    "for i in range(1000,4000):\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "\n",
    "        #components\n",
    "        mod_res = mxp.mesoscale.get_mod(g_multi=net.g_multi, n_iter=1)\n",
    "        \n",
    "        if not os.path.isfile(\"../Data/Mod/\"+nam+\"_mods.txt\"):\n",
    "            np.savetxt(X=[mod_res[0]], fname=\"../Data/Mod/\"+nam+\"_mods.txt\", fmt=\"%d\")\n",
    "        else:\n",
    "            mods_list = np.loadtxt(\"../Data/Mod/\"+nam+\"_mods.txt\")\n",
    "            if mods_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[mods_list],mod_res[0]]), fname=\"../Data/Mod/\"+nam+\"_mods.txt\", fmt=\"%d\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([mods_list,mod_res[0]]), fname=\"../Data/Mod/\"+nam+\"_mods.txt\", fmt=\"%d\")\n",
    "                \n",
    "        if not os.path.isfile(\"../Data/Mod/\"+nam+\"_mody.txt\"):\n",
    "            np.savetxt(X=[mod_res[1]], fname=\"../Data/Mod/\"+nam+\"_mody.txt\", fmt=\"%.5f\")\n",
    "        else:\n",
    "            mody_list = np.loadtxt(\"../Data/Mod/\"+nam+\"_mody.txt\")\n",
    "            if mody_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[mody_list],mod_res[1]]), fname=\"../Data/Mod/\"+nam+\"_mody.txt\", fmt=\"%.5f\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([mody_list,mod_res[1]]), fname=\"../Data/Mod/\"+nam+\"_mody.txt\", fmt=\"%.5f\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCC only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████▌                    | 980/2000 [26:35<23:39,  1.39s/it]"
     ]
    }
   ],
   "source": [
    "########################################LCC ONLY#######################################################\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationData_4vir/topology/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationData_4vir/topology/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "\n",
    "        #components\n",
    "        lcc_curr = len(mxp.topology.get_multi_LCC(net.g_list))\n",
    "\n",
    "        \n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\"):\n",
    "            np.savetxt(X=[lcc_curr], fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "        else:\n",
    "            lcc_list = np.loadtxt(\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\")\n",
    "            if lcc_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[lcc_list],[lcc_curr]]), fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([lcc_list,[lcc_curr]]), fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                      | 11/2000 [00:37<1:33:09,  2.81s/it]"
     ]
    }
   ],
   "source": [
    "##############################CENTR ONLY###########################################################\n",
    "\n",
    "biostr_df = pd.read_csv(\"../Data/data_BIOGRID/BIOGRID_homo_sapiens.nodes\", sep=\" \")\n",
    "biostr_map = dict(zip(biostr_df[\"nodeSymbol\"], biostr_df[\"nodeID\"]))\n",
    "\n",
    "for i in tqdm(range(1000,3000)):\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationDataALL_4vir/topology_p/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationDataALL_4vir/topology_p/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(biostr_map))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(biostr_map))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationDataALL_4vir/topology_p/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.4e\")\n",
    "        \"\"\"\n",
    "        #components\n",
    "        lcc_curr = len(mxp.topology.get_multi_LCC(net.g_list))\n",
    "        lic_curr = len(mxp.topology.get_multi_LIC(net.g_list))\n",
    "        lvc_curr = len(mxp.topology.get_multi_LVC(net.g_list, printt=False))\n",
    "        \n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\"):\n",
    "            np.savetxt(X=[lcc_curr], fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "        else:\n",
    "            lcc_list = np.loadtxt(\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\")\n",
    "            if lcc_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[lcc_list],[lcc_curr]]), fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([lcc_list,[lcc_curr]]), fname=\"../Data/ComponentsNew/LCC/\"+nam+\"_lcc.txt\", fmt=\"%d\")\n",
    "        \n",
    "        \n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/LIC/\"+nam+\"_lic.txt\"):\n",
    "            np.savetxt(X=[lic_curr], fname=\"../Data/ComponentsNew/LIC/\"+nam+\"_lic.txt\", fmt=\"%d\")\n",
    "        else:\n",
    "            lic_list = np.loadtxt(\"../Data/ComponentsNew/LIC/\"+nam+\"_lic.txt\")\n",
    "            if lic_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[lic_list],[lic_curr]]), fname=\"../Data/ComponentsNew/LIC/\"+nam+\"_lic.txt\", fmt=\"%d\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([lic_list,[lic_curr]]), fname=\"../Data/ComponentsNew/LIC/\"+nam+\"_lic.txt\", fmt=\"%d\")\n",
    "\n",
    "                \n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/LVC/\"+nam+\"_lvc.txt\"):\n",
    "            np.savetxt(X=[lvc_curr], fname=\"../Data/ComponentsNew/LVC/\"+nam+\"_lvc.txt\", fmt=\"%d\")\n",
    "        else:\n",
    "            lvc_list = np.loadtxt(\"../Data/ComponentsNew/LVC/\"+nam+\"_lvc.txt\")\n",
    "            if lvc_list.size==1:\n",
    "                np.savetxt(X=np.concatenate([[lvc_list],[lvc_curr]]), fname=\"../Data/ComponentsNew/LVC/\"+nam+\"_lvc.txt\", fmt=\"%d\")\n",
    "            else:\n",
    "                np.savetxt(X=np.concatenate([lvc_list,[lvc_curr]]), fname=\"../Data/ComponentsNew/LVC/\"+nam+\"_lvc.txt\", fmt=\"%d\")\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████▉                          | 490/1930 [3:48:30<15:24:19, 38.51s/it]"
     ]
    }
   ],
   "source": [
    "##################################COMPONENTS#######################################################à\n",
    "\n",
    "for i in tqdm(range(70,2000)):\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationData_4vir/topology/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationData_4vir/topology/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "        \n",
    "        #components\n",
    "        #lic_curr = mxp.topology.get_multi_LIC(net.g_list)\n",
    "        #if len(lic_curr)!=0:\n",
    "        #    lic_curr = itemgetter(*np.array(list(net.node_map.keys()))[lic_curr])(node_map_dict)\n",
    "        #if type(lic_curr)==int:\n",
    "        #    lic_curr = [lic_curr]\n",
    "        lvc_curr = mxp.topology.get_multi_LVC(net.g_list, printt=False)\n",
    "        if len(lvc_curr)!=0:\n",
    "            lvc_curr = itemgetter(*np.array(list(net.node_map.keys()))[lvc_curr])(node_map_dict)\n",
    "        if type(lvc_curr)==int:\n",
    "            lvc_curr = [lvc_curr]\n",
    "    \n",
    "        #if not os.path.isfile(\"../Data/ComponentsNew/LIC_all/\"+nam+\".txt\"):\n",
    "        #    mxp.utils.writeComponent(fname=\"../Data/ComponentsNew/LIC_all/\"+nam+\".txt\", ensemble=[lic_curr])\n",
    "        #else:\n",
    "        #    lic_list = mxp.utils.readComponent(\"../Data/ComponentsNew/LIC_all/\"+nam+\".txt\")\n",
    "        #    lic_list.append(lic_curr)\n",
    "        #    mxp.utils.writeComponent(ensemble=lic_list, fname=\"../Data/ComponentsNew/LIC_all/\"+nam+\".txt\")\n",
    "\n",
    "        if not os.path.isfile(\"../Data/ComponentsNew/LVC_all/\"+nam+\".txt\"):\n",
    "            mxp.utils.writeComponent(fname=\"../Data/ComponentsNew/LVC_all/\"+nam+\".txt\", ensemble=[lvc_curr])\n",
    "        else:\n",
    "            lvc_list = mxp.utils.readComponent(\"../Data/ComponentsNew/LVC_all/\"+nam+\".txt\")\n",
    "            lvc_list.append(lvc_curr)\n",
    "            mxp.utils.writeComponent(ensemble=lvc_list, fname=\"../Data/ComponentsNew/LVC_all/\"+nam+\".txt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deleting onco virus 67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onco_virus_indexes = np.where(np.array(np.all([virus_metadata[\"neigh_order\"]==NEIGH_ORDER, virus_metadata[\"isOncogenic\"] == True], axis=0)))[0]\n",
    "onco_virus_indexes_del = np.delete(onco_virus_indexes, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_iters = 2000\n",
    "\n",
    "#N\n",
    "n_virus_indexes = SamplingForNoco(n_iters, group_dim=4, random_seed=41252145)\n",
    "\n",
    "\n",
    "#N1O\n",
    "n1o_virus_indexes = []\n",
    "n1o_sampling = SamplingForNoco(n_iters, group_dim=3, random_seed=456)\n",
    "for i in range(len(n1o_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes_del)\n",
    "    n1o_virus_indexes.append(np.concatenate([n1o_sampling[i], [onco_pick]]))\n",
    "\n",
    "#N2O\n",
    "n2o_virus_indexes = []\n",
    "n2o_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=17521)\n",
    "for i in range(len(n2o_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes_del, 2)\n",
    "    n2o_virus_indexes.append(np.concatenate([n2o_sampling[i], onco_pick]))\n",
    "    \n",
    "#N3O\n",
    "comb = list(itertools.combinations(range(7), 3))\n",
    "o1n_onco_comb = [list(onco_virus_indexes_del[list(comb[i])]) for i in range(len(comb))]\n",
    "\n",
    "nonco_positions = np.where(np.all([np.array(virus_metadata[\"virus\"]!=\"Human_SARS_coronavirus_2\"),\n",
    "                                  np.array(virus_metadata[\"virus_short\"]!=\"Lymphocytic_choriomeningitis_virus\"),\n",
    "                                  np.array(virus_metadata[\"neigh_order\"]==NEIGH_ORDER), \n",
    "                                  np.array(virus_metadata[\"isOncogenic\"]==False)],\n",
    "                                  axis=0))[0]\n",
    "n3o_virus_indexes = random.sample(set(itertools.product(np.arange(len(o1n_onco_comb)), nonco_positions)), n_iters)\n",
    "n3o_virus_indexes = [np.concatenate([list(o1n_onco_comb[i[0]]), [i[1]]]) for i in n3o_virus_indexes]\n",
    "\n",
    "#O\n",
    "comb = list(itertools.combinations(range(7), 4))\n",
    "o_virus_indexes = np.array([list(onco_virus_indexes_del[list(comb[i])]) for i in range(len(comb))])\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#N1S\n",
    "Snonco_nonco_samples = SamplingForNoco(n_iters, group_dim=3, random_seed=4563)\n",
    "n1s_virus_indexes = np.concatenate([Snonco_nonco_samples, np.repeat(Sars_pos,n_iters).reshape([n_iters,1])], axis=1)\n",
    "\n",
    "#N1O1S\n",
    "n1o1s_virus_indexes = []\n",
    "n1o1s_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=783)\n",
    "for i in range(len(n1o1s_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes_del)\n",
    "    n1o1s_virus_indexes.append(np.concatenate([n1o1s_sampling[i], [onco_pick], [Sars_pos]]))\n",
    "    \n",
    "#N2O1S\n",
    "n2o1s_virus_indexes = []\n",
    "n2o1s_sampling = SamplingForNoco(n_iters, group_dim=1, random_seed=154)\n",
    "for i in range(len(n2o1s_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes_del,2)\n",
    "    n2o1s_virus_indexes.append(np.concatenate([n2o1s_sampling[i], onco_pick, [Sars_pos]]))\n",
    "    \n",
    "#O1S\n",
    "comb = list(itertools.combinations(range(7), 3))\n",
    "Sars_pos = np.where(np.array(np.all([virus_metadata[\"neigh_order\"]==NEIGH_ORDER, virus_metadata[\"virus\"]==\"Human_SARS_coronavirus_2\"], axis=0)))[0][0]\n",
    "o1s_virus_indexes = np.array([list(onco_virus_indexes_del[list(comb[i])])+[Sars_pos] for i in range(len(comb))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_lists = [#n_virus_indexes,\n",
    "               n1o_virus_indexes, \n",
    "               n2o_virus_indexes, \n",
    "               n3o_virus_indexes,\n",
    "               #o_virus_indexes, \n",
    "               #n1s_virus_indexes,\n",
    "               #n1o1s_virus_indexes,\n",
    "               #n2o1s_virus_indexes,\n",
    "               #o1s_virus_indexes\n",
    "               ]\n",
    "\n",
    "names_lists=[#\"n\", \n",
    "             \"n1o\", \n",
    "             \"n2o\", \n",
    "             \"n3o\", \n",
    "             #\"o\", \n",
    "             #\"n1s\", \n",
    "             #\"n1o1s\", \n",
    "             #\"n2o1s\", \n",
    "             #\"o1s\"\n",
    "             ]\n",
    "print(dict(zip(names_lists, [len(ioo) for ioo in index_lists])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = net_onco\n",
    "\n",
    "for i in range(2000):\n",
    "    print(i)\n",
    "    for nam, lst in tqdm(zip(names_lists, index_lists)):\n",
    "        if not os.path.isdir(\"../Data/ClassificationData_4vir/train/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationData_4vir/train/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(node_map_dict))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(node_map_dict))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationData_4vir/train/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.6f\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always with virus 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters=100\n",
    "#N1O\n",
    "n1o_virus_indexes = []\n",
    "n1o_sampling = SamplingForNoco(n_iters, group_dim=3, random_seed=456)\n",
    "for i in range(len(n1o_sampling)):\n",
    "    #onco_pick = np.random.choice(onco_virus_indexes_del)\n",
    "    n1o_virus_indexes.append(np.concatenate([n1o_sampling[i], [67]]))\n",
    "\n",
    "#N2O\n",
    "n2o_virus_indexes = []\n",
    "n2o_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=17521)\n",
    "for i in range(len(n2o_sampling)):\n",
    "    onco_pick = np.random.choice(onco_virus_indexes_del, 1)\n",
    "    n2o_virus_indexes.append(np.concatenate([n2o_sampling[i], onco_pick,[67]]))\n",
    "    \n",
    "#N3O\n",
    "comb = list(itertools.combinations(range(7), 2))\n",
    "o1n_onco_comb = [list(onco_virus_indexes_del[list(comb[i])]) for i in range(len(comb))]\n",
    "\n",
    "nonco_positions = np.where(np.all([np.array(virus_metadata[\"virus\"]!=\"Human_SARS_coronavirus_2\"),\n",
    "                                  np.array(virus_metadata[\"virus_short\"]!=\"Lymphocytic_choriomeningitis_virus\"),\n",
    "                                  np.array(virus_metadata[\"neigh_order\"]==NEIGH_ORDER), \n",
    "                                  np.array(virus_metadata[\"isOncogenic\"]==False)],\n",
    "                                  axis=0))[0]\n",
    "n3o_virus_indexes = set(itertools.product(np.arange(len(o1n_onco_comb)), nonco_positions))\n",
    "n3o_virus_indexes = [np.concatenate([list(o1n_onco_comb[i[0]]), [i[1]],[67]]) for i in n3o_virus_indexes]\n",
    "n3o_virus_indexes = random.sample(n3o_virus_indexes, n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n1o': 100, 'n2o': 100, 'n3o': 100}\n"
     ]
    }
   ],
   "source": [
    "index_lists = [#n_virus_indexes,\n",
    "               n1o_virus_indexes, \n",
    "               n2o_virus_indexes, \n",
    "               n3o_virus_indexes,\n",
    "               #o_virus_indexes, \n",
    "               #n1s_virus_indexes,\n",
    "               #n1o1s_virus_indexes,\n",
    "               #n2o1s_virus_indexes,\n",
    "               #o1s_virus_indexes\n",
    "               ]\n",
    "\n",
    "names_lists=[#\"n\", \n",
    "             \"n1o\", \n",
    "             \"n2o\", \n",
    "             \"n3o\", \n",
    "             #\"o\", \n",
    "             #\"n1s\", \n",
    "             #\"n1o1s\", \n",
    "             #\"n2o1s\", \n",
    "             #\"o1s\"\n",
    "             ]\n",
    "print(dict(zip(names_lists, [len(ioo) for ioo in index_lists])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [06:38<00:00,  7.97s/it]\n"
     ]
    }
   ],
   "source": [
    "net = net_onco\n",
    "\n",
    "for i in tqdm(range(50,100)):\n",
    "    #print(i)\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationData_4vir/val/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationData_4vir/val/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex(lst[i], target_folder=target_folder, virus_metadata=virus_metadata)\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(node_map_dict))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(node_map_dict))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationData_4vir/val/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.6f\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Synt Viruses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 330 - Nonco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(123451)\n",
    "n_iters=100\n",
    "#N1YN\n",
    "n1yn_sampling = SamplingForNoco(n_iters, group_dim=3, random_seed=456)\n",
    "n1yn_virus_dir = [[\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[i, \"virus_short\"]) for i in ns] for ns in n1yn_sampling]\n",
    "for i in range(len(n1yn_sampling)):\n",
    "    n1yn_virus_dir[i].append(\"../Data/SynteticViruses/330_Nonco/\"+str(np.random.randint(50)))\n",
    "    \n",
    "n_iters=100\n",
    "#N1O\n",
    "\n",
    "n1o1yn_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=456)\n",
    "n1o1yn_virus_dir = [[\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[i, \"virus_short\"]) for i in ns] for ns in n1o1yn_sampling]\n",
    "for i in range(len(n1o1yn_sampling)):\n",
    "    n1o1yn_virus_dir[i].append(\"../Data/SynteticViruses/330_Nonco/\"+str(np.random.randint(50)))\n",
    "    n1o1yn_virus_dir[i].append(\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[np.random.choice(onco_virus_indexes), \"virus_short\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n1yn': 100, 'n1o1yn': 100}\n"
     ]
    }
   ],
   "source": [
    "index_lists = [n1yn_virus_dir,\n",
    "               n1o1yn_virus_dir\n",
    "               ]\n",
    "\n",
    "names_lists=[\"n1yn\", \n",
    "             \"n1o1yn\" \n",
    "             ]\n",
    "print(dict(zip(names_lists, [len(ioo) for ioo in index_lists])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biostr_df = pd.read_csv(\"../Data/data_BIOGRID/BIOGRID_homo_sapiens.nodes\", sep=\" \")\n",
    "\n",
    "biostr_map = dict(zip(biostr_df[\"nodeSymbol\"], biostr_df[\"nodeID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    #print(i)\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationDataALL_4vir/Test_Synt_330Nonco/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationDataALL_4vir/Test_Synt_330Nonco/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex_from_dirlist(lst[i])\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(biostr_map))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(biostr_map))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationDataALL_4vir/Test_Synt_330Nonco/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.3e\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distr - Sars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(123451)\n",
    "n_iters=100\n",
    "#N1YN\n",
    "n1yn_sampling = SamplingForNoco(n_iters, group_dim=3, random_seed=456)\n",
    "n1yn_virus_dir = [[\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[i, \"virus_short\"]) for i in ns] for ns in n1yn_sampling]\n",
    "for i in range(len(n1yn_sampling)):\n",
    "    n1yn_virus_dir[i].append(\"../Data/SynteticViruses/Distr_Sars/\"+str(np.random.randint(50)))\n",
    "    \n",
    "n_iters=100\n",
    "#N1O\n",
    "\n",
    "n1o1yn_sampling = SamplingForNoco(n_iters, group_dim=2, random_seed=456)\n",
    "n1o1yn_virus_dir = [[\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[i, \"virus_short\"]) for i in ns] for ns in n1o1yn_sampling]\n",
    "for i in range(len(n1o1yn_sampling)):\n",
    "    n1o1yn_virus_dir[i].append(\"../Data/SynteticViruses/Distr_Sars/\"+str(np.random.randint(50)))\n",
    "    n1o1yn_virus_dir[i].append(\"../Data/SynteticViruses/Original/\"+str(virus_metadata.loc[np.random.choice(onco_virus_indexes), \"virus_short\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n1yn': 100, 'n1o1yn': 100}\n"
     ]
    }
   ],
   "source": [
    "index_lists = [n1yn_virus_dir,\n",
    "               n1o1yn_virus_dir\n",
    "               ]\n",
    "\n",
    "names_lists=[\"n1yn\", \n",
    "             \"n1o1yn\" \n",
    "             ]\n",
    "print(dict(zip(names_lists, [len(ioo) for ioo in index_lists])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [04:00<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    #print(i)\n",
    "    for nam, lst in zip(names_lists, index_lists):\n",
    "        if not os.path.isdir(\"../Data/ClassificationDataALL_4vir/Test_Synt_DistrSars/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationDataALL_4vir/Test_Synt_DistrSars/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex_from_dirlist(lst[i])\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(biostr_map))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(biostr_map))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationDataALL_4vir/Test_Synt_DistrSars/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.3e\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COEXPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "[\"a\",\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "n_combs = [[\"../Data/data_STRING/coexpr_vir/nonco/\"+a for a in np.random.choice(os.listdir(\"../Data/data_STRING/coexpr_vir/nonco\"),4, replace=False)] for i in range(3000)]\n",
    "n1o_combs = [np.concatenate([[\"../Data/data_STRING/coexpr_vir/nonco/\"+a for a in np.random.choice(os.listdir(\"../Data/data_STRING/coexpr_vir/nonco\"),3, replace=False)], [\"../Data/data_STRING/coexpr_vir/onco/\"+a for a in np.random.choice(os.listdir(\"../Data/data_STRING/coexpr_vir/onco\"),1)]]) for i in range(3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../Data/data_STRING/coexpr_vir/nonco/Reovirus_type_1_strain_Lang',\n",
       "       '../Data/data_STRING/coexpr_vir/nonco/Avian_leukosis_virus_RSA',\n",
       "       '../Data/data_STRING/coexpr_vir/nonco/Norwalk_virus_strain_GI_Human_United_States_Norwalk_1968',\n",
       "       '../Data/data_STRING/coexpr_vir/onco/Human_T-cell_leukemia_virus_1_isolate_Caribbea_HS-35_subtype_A'],\n",
       "      dtype='<U98')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1o_combs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                     | 222/3000 [02:26<26:28,  1.75it/s]"
     ]
    }
   ],
   "source": [
    "coexpr_df = pd.read_csv(\"../Data/data_STRING/coexpr.nodes\", sep=\" \")\n",
    "coexpr_map = dict(zip(coexpr_df[\"Prot\"], coexpr_df[\"ID\"]))\n",
    "\n",
    "for i in tqdm(range(3000)):\n",
    "    for nam, lst in zip([\"n\",\"n1o\"], [n_combs,n1o_combs]):\n",
    "        if not os.path.isdir(\"../Data/ClassificationDataALL_4vir/topology_coex/\"+nam):\n",
    "            os.mkdir(\"../Data/ClassificationDataALL_4vir/topology_coex/\"+nam)\n",
    "        \n",
    "        net = mxp.VirusMultiplex_from_dirlist(lst[i])\n",
    "        tensor = mxp.build.get_node_tensor_from_network_list(net.g_list)\n",
    "        \n",
    "        \n",
    "        res_df = mxp.versatility.get_multi_RW_centrality_edge_colored(node_tensor=tensor, cval=0.15)\n",
    "        \n",
    "\n",
    "        list_res = np.array(list(net.node_map.keys()))[res_df.sort_values(\"vers\", ascending=False).index[:50]]\n",
    "\n",
    "        centr_norm = np.zeros(len(biostr_map))\n",
    "        centr_norm[np.array(itemgetter(*list(net.node_map.keys()))(coexpr_map))] = res_df[\"vers\"].to_numpy()\n",
    "        centr_norm=centr_norm/max(centr_norm)\n",
    "        \n",
    "        np.savetxt(X=centr_norm, fname=\"../Data/ClassificationDataALL_4vir/topology_coex/\"+nam+\"/\"+str(i)+\".txt\", fmt=\"%.4e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
